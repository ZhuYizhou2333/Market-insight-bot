"""
AI Analyzer for News Data
ä½¿ç”¨é˜¿é‡Œäº‘ DashScope (Qwen) åˆ†ææ–°é—»æ¶ˆæ¯
"""
import json
import os
from collections import deque
from datetime import datetime
from typing import Dict, List, Optional

from dashscope import Generation
from dashscope.api_entities.dashscope_response import GenerationResponse

from utils.logger import logger
from utils.email_sender import send_markdown_email


class NewsAnalyzer:
    """
    åˆ†æ Telegram æ–°é—»æ¶ˆæ¯ï¼Œæä¾›æ‘˜è¦å’Œå¸‚åœºæ³¢åŠ¨ç‡åˆ¤æ–­
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "qwen-plus-latest",
        message_buffer_size: int = 1000,
        analysis_interval: int = 1000,
        summary_interval_channel: int = 50,
        summary_interval_group: int = 1000,
        summary_message_count: int = 100,
        volatility_message_count: int = 500,
    ):
        """
        åˆå§‹åŒ–æ–°é—»åˆ†æå™¨

        Args:
            api_key: é˜¿é‡Œäº‘ DashScope API Keyï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            message_buffer_size: æ¶ˆæ¯ç¼“å†²åŒºå¤§å°
            analysis_interval: åˆ†æé—´éš”ï¼ˆæ¶ˆæ¯æ•°é‡ï¼‰ï¼Œç”¨äºæ³¢åŠ¨ç‡ç­‰å‘¨æœŸæ€§åˆ†æ
            summary_interval_channel: é¢‘é“ï¼ˆæ–°é—»ï¼‰æ‘˜è¦é—´éš”
            summary_interval_group: ç¤¾ç¾¤ï¼ˆç¾¤ç»„ï¼‰æ‘˜è¦é—´éš”
            summary_message_count: æ‘˜è¦æ—¶é‡‡æ ·çš„æœ€è¿‘æ¶ˆæ¯æ•°é‡
            volatility_message_count: æ³¢åŠ¨ç‡åˆ†ææ—¶é‡‡æ ·çš„æœ€è¿‘æ¶ˆæ¯æ•°é‡
        """
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
        if not self.api_key:
            raise ValueError(
                "DASHSCOPE_API_KEY not found in environment variables or parameters"
            )

        self.model = model
        self.message_buffer_size = message_buffer_size
        self.analysis_interval = analysis_interval
        self.summary_interval_channel = summary_interval_channel
        self.summary_interval_group = summary_interval_group
        self.summary_message_count = summary_message_count
        self.volatility_message_count = volatility_message_count

        # æ¶ˆæ¯ç¼“å†²åŒº
        self.message_buffer = deque(maxlen=message_buffer_size)
        self.message_count = 0
        self.last_analysis_count = 0
        # æŒ‰ç±»å‹è®¡æ•°ä¸ä¸Šä¸€æ¬¡æ‘˜è¦ä½ç½®
        self.channel_message_count = 0
        self.group_message_count = 0
        self.last_channel_summary_count = 0
        self.last_group_summary_count = 0

        logger.info(f"NewsAnalyzer initialized with model: {model}")

    def add_message(self, message_data: Dict) -> None:
        """
        æ·»åŠ æ–°æ¶ˆæ¯åˆ°ç¼“å†²åŒº

        Args:
            message_data: æ¶ˆæ¯æ•°æ®å­—å…¸ï¼ŒåŒ…å« channel, text, date ç­‰å­—æ®µ
        """
        self.message_buffer.append(message_data)
        self.message_count += 1

        # è¯†åˆ«æ¶ˆæ¯ç±»å‹
        msg_type = (message_data.get("message_type") or "unknown").lower()
        if msg_type == "channel":
            self.channel_message_count += 1
            # è¾¾åˆ°é¢‘é“æ‘˜è¦é—´éš”åˆ™ç”Ÿæˆé¢‘é“æ‘˜è¦
            if (
                self.channel_message_count - self.last_channel_summary_count
                >= self.summary_interval_channel
            ):
                summary = self.summarize_recent_messages(
                    num_messages=self.summary_message_count, message_type="channel"
                )
                if summary:
                    logger.success(f"[Channel Summary] {summary}")
                else:
                    logger.warning("[Channel Summary] Failed to generate summary")
                self.last_channel_summary_count = self.channel_message_count

        elif msg_type == "group":
            self.group_message_count += 1
            # è¾¾åˆ°ç¤¾ç¾¤æ‘˜è¦é—´éš”åˆ™ç”Ÿæˆç¤¾ç¾¤æ‘˜è¦
            if (
                self.group_message_count - self.last_group_summary_count
                >= self.summary_interval_group
            ):
                summary = self.summarize_recent_messages(
                    num_messages=self.summary_message_count, message_type="group"
                )
                if summary:
                    logger.success(f"[Group Summary] {summary}")
                else:
                    logger.warning("[Group Summary] Failed to generate summary")
                self.last_group_summary_count = self.group_message_count

        # å‘¨æœŸæ€§è¿›è¡Œæ³¢åŠ¨ç‡åˆ†æ
        if self.message_count - self.last_analysis_count >= self.analysis_interval:
            self.analyze_messages()
            self.last_analysis_count = self.message_count

    def _call_qwen_api(self, prompt: str, system_prompt: str = None) -> Optional[str]:
        """
        è°ƒç”¨åƒé—® API

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯

        Returns:
            API è¿”å›çš„æ–‡æœ¬å†…å®¹
        """
        try:
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})

            response: GenerationResponse = Generation.call(
                api_key=self.api_key,
                model=self.model,
                messages=messages,
                result_format="message",
            )

            if response.status_code == 200:
                return response.output.choices[0].message.content
            else:
                logger.error(
                    f"Qwen API call failed: {response.code} - {response.message}"
                )
                return None

        except Exception as e:
            logger.error(f"Error calling Qwen API: {e}")
            return None

    def summarize_recent_messages(
        self, num_messages: int = 100, message_type: Optional[str] = None
    ) -> Optional[str]:
        """
        å¯¹æœ€è¿‘ N æ¡æ¶ˆæ¯è¿›è¡Œæ‘˜è¦

        Args:
            num_messages: è¦æ‘˜è¦çš„æ¶ˆæ¯æ•°é‡

        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        if len(self.message_buffer) == 0:
            logger.warning("No messages in buffer to summarize")
            return None

        # è·å–æœ€è¿‘çš„ N æ¡æ¶ˆæ¯ï¼›å¦‚æœæŒ‡å®šäº†ç±»å‹ï¼Œåˆ™æŒ‰ç±»å‹è¿‡æ»¤
        if message_type:
            filtered = [
                m for m in self.message_buffer if (m.get("message_type") or "").lower() == message_type
            ]
            recent_messages = filtered[-num_messages:]
        else:
            recent_messages = list(self.message_buffer)[-num_messages:]

        # æ„å»ºæ¶ˆæ¯æ–‡æœ¬
        message_texts = []
        for msg in recent_messages:
            channel = msg.get("channel", "Unknown")
            text = msg.get("text", "")
            date = msg.get("date", "")
            if text:
                message_texts.append(f"[{channel} - {date}]: {text}")

        combined_text = "\n\n".join(message_texts)

        # ...existing code...
        system_prompt = """ä½ æ˜¯åŠ å¯†è´§å¸å¸‚åœºäº‹ä»¶ä¸ä»·æ ¼å½±å“åˆ†æåŠ©æ‰‹ã€‚ä»…åŸºäºç»™å®šçš„ Telegram æ–‡æœ¬ï¼Œè¯†åˆ«æ­£åœ¨å‘ç”Ÿçš„å¯éªŒè¯äº‹ä»¶ï¼Œå¹¶ç”¨å…‹åˆ¶çš„å™äº‹ä½“æ€»ç»“å…¶å¯¹ä»·æ ¼çš„å½±å“ã€‚

å¿…é¡»éµå®ˆï¼š
- åªä½¿ç”¨æ¶ˆæ¯ä¸­çš„ä¿¡æ¯ï¼›ä¸å¾—è¡¥å……å¸¸è¯†æˆ–å¤–éƒ¨æ–°é—»ï¼›ä¸å¾—ç¼–é€ ä»»ä½•æ•°å­—ã€æ¥æºæˆ–å¼•è¨€ã€‚
- æ¶¨è·Œå¹…/ä»·æ ¼/æ—¶é—´çª—å£å¦‚æœªåœ¨æ–‡æœ¬å‡ºç°ï¼Œå†™â€œæœªè§æ˜ç¡®æ•°å€¼/æ—¶é—´â€ã€‚
- åŸå› ä¸ç¡®å®šæ—¶å†™â€œåŸå› ä¸æ˜/å¾…è§‚å¯Ÿâ€ã€‚å¦‚ä½œæ¨æµ‹ï¼Œéœ€æ˜ç¡®æ ‡æ³¨â€œå¯èƒ½å› â€¦â€¦ï¼ˆæ®æ¶ˆæ¯æ‰€è¿°/å¤šæ¡æåŠï¼‰â€ã€‚
- é¿å…å£è¯­åŒ–ä¸ç…½åŠ¨æ€§è¯æ±‡ï¼Œé¿å…è¡¨æƒ…ç¬¦å·ä¸å¤¸å¼ ä¿®è¾ã€‚

è¾“å‡ºæ–¹å¼ï¼ˆå™äº‹ä½“ï¼Œéç»“æ„åŒ–ï¼‰ï¼š
- æ¯ä¸ªçƒ­ç‚¹ç”¨2-3å¥å®¢è§‚é™ˆè¿°ï¼šå…ˆæ¦‚è¿°äº‹ä»¶ï¼Œå†ç»™å‡ºä»·æ ¼å½±å“ï¼ˆè‹¥æœ‰ï¼‰ï¼Œæœ€åè¯´æ˜å¯èƒ½åŸå› ä¸ä¸ç¡®å®šæ€§ï¼›å¿…è¦æ—¶ç©¿æ’ä¸€æ¡åŸæ–‡å¼•è¿°ã€‚
- è‹¥æ— æ˜æ˜¾çƒ­ç‚¹ï¼Œä»…è¾“å‡ºï¼šæš‚æ— æ˜æ˜¾çƒ­ç‚¹ã€‚"""
# ...existing code...
        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ {len(recent_messages)} æ¡æ¶ˆæ¯ï¼Œæç‚¼æ­£åœ¨å‘ç”Ÿçš„çƒ­ç‚¹äº‹ä»¶åŠå…¶å¯¹ä»·æ ¼çš„å½±å“ã€‚åªä¾æ®æ¶ˆæ¯å†…å®¹ä½œç­”ï¼›æ— æ³•åˆ¤æ–­çš„é¡¹è¯·ç›´è¿°ï¼ˆå¦‚â€œæœªè§æ˜ç¡®æ•°å€¼â€â€œåŸå› ä¸æ˜/å¾…è§‚å¯Ÿâ€ï¼‰ã€‚è¾“å‡ºä½¿ç”¨ç®€æ´å™äº‹ä½“ï¼Œä¸è¦ä½¿ç”¨åˆ—è¡¨æˆ–å°æ ‡é¢˜ã€‚

{combined_text}

è¯·ç›´æ¥ç»™å‡ºå™è¿°ï¼›æ— çƒ­ç‚¹åˆ™ä»…è¾“å‡ºâ€œæš‚æ— æ˜æ˜¾çƒ­ç‚¹â€ã€‚"""
# ...existing code...

        summary = self._call_qwen_api(user_prompt, system_prompt)
        return summary

    def analyze_market_volatility(
        self, num_messages: int = 500
    ) -> Optional[Dict[str, any]]:
        """
        åˆ¤æ–­å¸‚åœºæ³¢åŠ¨ç‡å’Œç¤¾ç¾¤æ´»è·ƒåº¦

        Args:
            num_messages: åˆ†æçš„æ¶ˆæ¯æ•°é‡

        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ï¼š
            {
                "volatility_increased": bool,
                "activity_increased": bool,
                "summary": str,
                "hot_topics": List[str],
                "confidence": float
            }
        """
        if len(self.message_buffer) == 0:
            logger.warning("No messages in buffer to analyze")
            return None

        # è·å–æœ€è¿‘çš„ N æ¡æ¶ˆæ¯
        recent_messages = list(self.message_buffer)[-num_messages:]

        # æ„å»ºæ¶ˆæ¯æ–‡æœ¬
        message_texts = []
        for msg in recent_messages:
            channel = msg.get("channel", "Unknown")
            text = msg.get("text", "")
            date = msg.get("date", "")
            if text:
                message_texts.append(f"[{channel} - {date}]: {text}")

        combined_text = "\n\n".join(message_texts)

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªåŠ å¯†è´§å¸å¸‚åœºæƒ…ç»ªåˆ†æä¸“å®¶ã€‚ä½ éœ€è¦åˆ†æ Telegram æ¶ˆæ¯ï¼Œåˆ¤æ–­å¸‚åœºæ³¢åŠ¨ç‡å’Œç¤¾ç¾¤æ´»è·ƒåº¦ã€‚

ä½ éœ€è¦åˆ¤æ–­ï¼š
1. å¸‚åœºæ³¢åŠ¨ç‡æ˜¯å¦ä¸Šå‡ï¼ˆåŸºäºä»·æ ¼è®¨è®ºé¢‘ç‡ã€ç´§æ€¥è¯æ±‡ã€æƒ…ç»ªå¼ºåº¦ï¼‰
2. ç¤¾ç¾¤æ´»è·ƒåº¦æ˜¯å¦ä¸Šå‡ï¼ˆåŸºäºæ¶ˆæ¯é¢‘ç‡ã€è®¨è®ºçƒ­åº¦ã€äº’åŠ¨æ€§ï¼‰
3. å½“å‰çš„çƒ­ç‚¹è¯é¢˜

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼š
{
    "volatility_increased": true/false,
    "activity_increased": true/false,
    "summary": "ç®€çŸ­è¯´æ˜åŸå› å’Œå¸‚åœºçŠ¶å†µ",
    "hot_topics": ["è¯é¢˜1", "è¯é¢˜2", "è¯é¢˜3"],
    "confidence": 0.0-1.0
}"""

        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ {len(recent_messages)} æ¡åŠ å¯†è´§å¸ Telegram æ¶ˆæ¯ï¼Œåˆ¤æ–­å¸‚åœºæ³¢åŠ¨ç‡å’Œç¤¾ç¾¤æ´»è·ƒåº¦æ˜¯å¦ä¸Šå‡ï¼š

{combined_text}

è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¿”å›åˆ†æç»“æœã€‚"""

        response = self._call_qwen_api(user_prompt, system_prompt)

        if not response:
            return None

        try:
            # å°è¯•æå– JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown ä»£ç å—ï¼‰
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.startswith("```"):
                response = response[3:]
            if response.endswith("```"):
                response = response[:-3]

            result = json.loads(response.strip())
            return result

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {e}")
            logger.error(f"Response was: {response}")
            return None

    def analyze_messages(self) -> None:
        """
        æ‰§è¡Œå®šæœŸåˆ†æï¼šæ¯ N æ¡æ¶ˆæ¯è¿›è¡Œä¸€æ¬¡æ‘˜è¦å’Œæ³¢åŠ¨ç‡åˆ¤æ–­
        """
        logger.info(
            f"Starting analysis at message count: {self.message_count} "
            f"(buffer size: {len(self.message_buffer)})"
        )

        # åˆ†æå¸‚åœºæ³¢åŠ¨ç‡ï¼ˆæ‘˜è¦æ”¹ä¸ºæŒ‰ç±»å‹ç‹¬ç«‹è§¦å‘ï¼Œä½†åœ¨é‚®ä»¶ä¸­æ±‡æ€»å±•ç¤ºï¼‰
        volatility_result = self.analyze_market_volatility(
            num_messages=self.volatility_message_count
        )

        if volatility_result:
            logger.info(f"Volatility Analysis Result: {json.dumps(volatility_result, ensure_ascii=False, indent=2)}")

            # é¢‘é“ä¸ç¤¾ç¾¤åˆ†åˆ«ç”Ÿæˆæ‘˜è¦ï¼Œç”¨äºç»Ÿä¸€é‚®ä»¶å†…å®¹
            channel_summary = self.summarize_recent_messages(
                num_messages=self.summary_message_count, message_type="channel"
            )
            group_summary = self.summarize_recent_messages(
                num_messages=self.summary_message_count, message_type="group"
            )

            # 3. å¦‚æœæ³¢åŠ¨ç‡æˆ–æ´»è·ƒåº¦ä¸Šå‡ï¼Œå‘é€é‚®ä»¶ï¼ˆåŒ…å«æ–°é—»ä¸ç¤¾ç¾¤ä¸¤éƒ¨åˆ†æ‘˜è¦ï¼‰
            if volatility_result.get("volatility_increased") or volatility_result.get(
                "activity_increased"
            ):
                self._send_alert_email(volatility_result, channel_summary, group_summary)
            else:
                logger.info("No significant market volatility or activity increase detected")
        else:
            logger.warning("Failed to analyze market volatility")

    def _send_alert_email(
        self, volatility_result: Dict, channel_summary: Optional[str], group_summary: Optional[str]
    ) -> None:
        """
        å‘é€å¸‚åœºæ³¢åŠ¨è­¦æŠ¥é‚®ä»¶

        Args:
            volatility_result: æ³¢åŠ¨ç‡åˆ†æç»“æœ
            channel_summary: æ–°é—»ï¼ˆé¢‘é“ï¼‰æ‘˜è¦
            group_summary: ç¤¾ç¾¤ï¼ˆç¾¤ç»„ï¼‰æ‘˜è¦
        """
        # æ„å»ºé‚®ä»¶å†…å®¹
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        volatility_status = (
            "ğŸ“ˆ **ä¸Šå‡**" if volatility_result.get("volatility_increased") else "ğŸ“Š æ­£å¸¸"
        )
        activity_status = (
            "ğŸ”¥ **ä¸Šå‡**" if volatility_result.get("activity_increased") else "ğŸ’¤ æ­£å¸¸"
        )

        hot_topics = volatility_result.get("hot_topics", [])
        hot_topics_md = (
            "\n".join([f"- {topic}" for topic in hot_topics])
            if hot_topics
            else "æš‚æ— æ˜æ˜¾çƒ­ç‚¹"
        )

        confidence = volatility_result.get("confidence", 0.0)
        confidence_bar = "ğŸŸ¢" * int(confidence * 10) + "âšª" * (10 - int(confidence * 10))

        email_content = f"""# ğŸš¨ å¸‚åœºæ³¢åŠ¨ç‡è­¦æŠ¥

**åˆ†ææ—¶é—´**: {timestamp}
**åˆ†ææ¶ˆæ¯æ•°**: {len(self.message_buffer)} æ¡
**ç´¯è®¡æ¶ˆæ¯æ•°**: {self.message_count} æ¡

---

## ğŸ“Š åˆ†æç»“æœ

### å¸‚åœºæ³¢åŠ¨ç‡
{volatility_status}

### ç¤¾ç¾¤æ´»è·ƒåº¦
{activity_status}

### ç½®ä¿¡åº¦
{confidence_bar} {confidence:.1%}

---

## ğŸ”¥ å½“å‰çƒ­ç‚¹è¯é¢˜

{hot_topics_md}

---

## ğŸ“ å¸‚åœºçŠ¶å†µè¯´æ˜

{volatility_result.get('summary', 'æš‚æ— è¯¦ç»†è¯´æ˜')}

---

## ğŸ“° æ–°é—»æ‘˜è¦ï¼ˆé¢‘é“ï¼‰

{channel_summary or 'æš‚æ— æ‘˜è¦'}

---

## ğŸ‘¥ ç¤¾ç¾¤æ‘˜è¦ï¼ˆç¾¤ç»„ï¼‰

{group_summary or 'æš‚æ— æ‘˜è¦'}

---

*æœ¬é‚®ä»¶ç”± Market Insight Bot è‡ªåŠ¨ç”Ÿæˆ*
*AI æ¨¡å‹: {self.model}*
"""

        subject = f"[Market Alert] å¸‚åœºæ³¢åŠ¨ç‡ä¸Šå‡ - {timestamp}"

        try:
            success = send_markdown_email(subject, email_content)
            if success:
                logger.success(f"Alert email sent successfully: {subject}")
            else:
                logger.error("Failed to send alert email")
        except Exception as e:
            logger.error(f"Error sending alert email: {e}")

    def get_stats(self) -> Dict[str, int]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        return {
            "total_messages": self.message_count,
            "buffer_size": len(self.message_buffer),
            "last_analysis_count": self.last_analysis_count,
            "next_analysis_at": self.last_analysis_count + self.analysis_interval,
            "channel_total_messages": self.channel_message_count,
            "group_total_messages": self.group_message_count,
            "next_channel_summary_at": self.last_channel_summary_count
            + self.summary_interval_channel,
            "next_group_summary_at": self.last_group_summary_count
            + self.summary_interval_group,
        }


# å…¨å±€åˆ†æå™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
_analyzer_instance = None


def get_analyzer(**kwargs) -> NewsAnalyzer:
    """
    è·å–å…¨å±€åˆ†æå™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Args:
        **kwargs: NewsAnalyzer åˆå§‹åŒ–å‚æ•°

    Returns:
        NewsAnalyzer å®ä¾‹
    """
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = NewsAnalyzer(**kwargs)
    return _analyzer_instance


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import time

    analyzer = NewsAnalyzer()

    # æ¨¡æ‹Ÿæ·»åŠ æ¶ˆæ¯
    test_messages = [
        {
            "channel": "CryptoNews",
            "text": "BTCçªç ´45000ç¾å…ƒï¼Œå¸‚åœºæƒ…ç»ªé«˜æ¶¨ï¼",
            "date": datetime.now().isoformat(),
            "message_id": 1,
        },
        {
            "channel": "TechFlow",
            "text": "ä»¥å¤ªåŠå³å°†å®Œæˆä¸Šæµ·å‡çº§ï¼Œè´¨æŠ¼ææ¬¾åŠŸèƒ½å¼€å¯",
            "date": datetime.now().isoformat(),
            "message_id": 2,
        },
        {
            "channel": "BlockBeats",
            "text": "Binanceå®£å¸ƒæ”¯æŒæ–°çš„è´¨æŠ¼äº§å“",
            "date": datetime.now().isoformat(),
            "message_id": 3,
        },
    ]

    for msg in test_messages:
        analyzer.add_message(msg)

    # æµ‹è¯•æ‘˜è¦åŠŸèƒ½
    print("\n=== æµ‹è¯•æ‘˜è¦åŠŸèƒ½ ===")
    summary = analyzer.summarize_recent_messages(num_messages=3)
    print(f"Summary: {summary}")

    # æµ‹è¯•æ³¢åŠ¨ç‡åˆ†æ
    print("\n=== æµ‹è¯•æ³¢åŠ¨ç‡åˆ†æ ===")
    volatility = analyzer.analyze_market_volatility(num_messages=3)
    print(f"Volatility: {json.dumps(volatility, ensure_ascii=False, indent=2)}")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n=== ç»Ÿè®¡ä¿¡æ¯ ===")
    stats = analyzer.get_stats()
    print(json.dumps(stats, indent=2))
