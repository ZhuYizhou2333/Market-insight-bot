"""
AI Analyzer for News Data
ä½¿ç”¨é˜¿é‡Œäº‘ DashScope (Qwen) åˆ†ææ–°é—»æ¶ˆæ¯
"""
import json
import os
from collections import deque
from datetime import datetime
from typing import Dict, List, Optional

from dashscope import Generation
from dashscope.api_entities.dashscope_response import GenerationResponse

from utils.logger import logger
from utils.email_sender import send_markdown_email


class NewsAnalyzer:
    """
    åˆ†æ Telegram æ–°é—»æ¶ˆæ¯ï¼Œæä¾›æ‘˜è¦å’Œå¸‚åœºæ³¢åŠ¨ç‡åˆ¤æ–­
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "qwen-plus-latest",
        message_buffer_size: int = 1000,
        analysis_interval: int = 1000,
    ):
        """
        åˆå§‹åŒ–æ–°é—»åˆ†æå™¨

        Args:
            api_key: é˜¿é‡Œäº‘ DashScope API Keyï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            message_buffer_size: æ¶ˆæ¯ç¼“å†²åŒºå¤§å°
            analysis_interval: åˆ†æé—´éš”ï¼ˆæ¶ˆæ¯æ•°é‡ï¼‰
        """
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
        if not self.api_key:
            raise ValueError(
                "DASHSCOPE_API_KEY not found in environment variables or parameters"
            )

        self.model = model
        self.message_buffer_size = message_buffer_size
        self.analysis_interval = analysis_interval

        # æ¶ˆæ¯ç¼“å†²åŒº
        self.message_buffer = deque(maxlen=message_buffer_size)
        self.message_count = 0
        self.last_analysis_count = 0

        logger.info(f"NewsAnalyzer initialized with model: {model}")

    def add_message(self, message_data: Dict) -> None:
        """
        æ·»åŠ æ–°æ¶ˆæ¯åˆ°ç¼“å†²åŒº

        Args:
            message_data: æ¶ˆæ¯æ•°æ®å­—å…¸ï¼ŒåŒ…å« channel, text, date ç­‰å­—æ®µ
        """
        self.message_buffer.append(message_data)
        self.message_count += 1

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›è¡Œåˆ†æ
        if self.message_count - self.last_analysis_count >= self.analysis_interval:
            self.analyze_messages()
            self.last_analysis_count = self.message_count

    def _call_qwen_api(self, prompt: str, system_prompt: str = None) -> Optional[str]:
        """
        è°ƒç”¨åƒé—® API

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯

        Returns:
            API è¿”å›çš„æ–‡æœ¬å†…å®¹
        """
        try:
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})

            response: GenerationResponse = Generation.call(
                api_key=self.api_key,
                model=self.model,
                messages=messages,
                result_format="message",
            )

            if response.status_code == 200:
                return response.output.choices[0].message.content
            else:
                logger.error(
                    f"Qwen API call failed: {response.code} - {response.message}"
                )
                return None

        except Exception as e:
            logger.error(f"Error calling Qwen API: {e}")
            return None

    def summarize_recent_messages(self, num_messages: int = 100) -> Optional[str]:
        """
        å¯¹æœ€è¿‘ N æ¡æ¶ˆæ¯è¿›è¡Œæ‘˜è¦

        Args:
            num_messages: è¦æ‘˜è¦çš„æ¶ˆæ¯æ•°é‡

        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        if len(self.message_buffer) == 0:
            logger.warning("No messages in buffer to summarize")
            return None

        # è·å–æœ€è¿‘çš„ N æ¡æ¶ˆæ¯
        recent_messages = list(self.message_buffer)[-num_messages:]

        # æ„å»ºæ¶ˆæ¯æ–‡æœ¬
        message_texts = []
        for msg in recent_messages:
            channel = msg.get("channel", "Unknown")
            text = msg.get("text", "")
            date = msg.get("date", "")
            if text:
                message_texts.append(f"[{channel} - {date}]: {text}")

        combined_text = "\n\n".join(message_texts)

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªåŠ å¯†è´§å¸å¸‚åœºåˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æ Telegram é¢‘é“çš„æ¶ˆæ¯ï¼Œæä¾›ç®€æ´å‡†ç¡®çš„æ‘˜è¦ã€‚
æ‘˜è¦åº”åŒ…å«ï¼š
1. ä¸»è¦è®¨è®ºçš„å¸ç§å’Œé¡¹ç›®
2. é‡è¦çš„å¸‚åœºäº‹ä»¶æˆ–æ–°é—»
3. ç¤¾åŒºå…³æ³¨çš„çƒ­ç‚¹è¯é¢˜
4. é‡è¦çš„ä»·æ ¼èµ°åŠ¿æˆ–æŠ€æœ¯åˆ†æè§‚ç‚¹

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šå’Œå®¢è§‚ã€‚"""

        user_prompt = f"""è¯·å¯¹ä»¥ä¸‹ {len(recent_messages)} æ¡åŠ å¯†è´§å¸ç›¸å…³çš„ Telegram æ¶ˆæ¯è¿›è¡Œæ‘˜è¦åˆ†æï¼š

{combined_text}

è¯·æä¾›ä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆ200-300å­—ï¼‰ã€‚"""

        summary = self._call_qwen_api(user_prompt, system_prompt)
        return summary

    def analyze_market_volatility(
        self, num_messages: int = 500
    ) -> Optional[Dict[str, any]]:
        """
        åˆ¤æ–­å¸‚åœºæ³¢åŠ¨ç‡å’Œç¤¾ç¾¤æ´»è·ƒåº¦

        Args:
            num_messages: åˆ†æçš„æ¶ˆæ¯æ•°é‡

        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ï¼š
            {
                "volatility_increased": bool,
                "activity_increased": bool,
                "summary": str,
                "hot_topics": List[str],
                "confidence": float
            }
        """
        if len(self.message_buffer) == 0:
            logger.warning("No messages in buffer to analyze")
            return None

        # è·å–æœ€è¿‘çš„ N æ¡æ¶ˆæ¯
        recent_messages = list(self.message_buffer)[-num_messages:]

        # æ„å»ºæ¶ˆæ¯æ–‡æœ¬
        message_texts = []
        for msg in recent_messages:
            channel = msg.get("channel", "Unknown")
            text = msg.get("text", "")
            date = msg.get("date", "")
            if text:
                message_texts.append(f"[{channel} - {date}]: {text}")

        combined_text = "\n\n".join(message_texts)

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªåŠ å¯†è´§å¸å¸‚åœºæƒ…ç»ªåˆ†æä¸“å®¶ã€‚ä½ éœ€è¦åˆ†æ Telegram æ¶ˆæ¯ï¼Œåˆ¤æ–­å¸‚åœºæ³¢åŠ¨ç‡å’Œç¤¾ç¾¤æ´»è·ƒåº¦ã€‚

ä½ éœ€è¦åˆ¤æ–­ï¼š
1. å¸‚åœºæ³¢åŠ¨ç‡æ˜¯å¦ä¸Šå‡ï¼ˆåŸºäºä»·æ ¼è®¨è®ºé¢‘ç‡ã€ç´§æ€¥è¯æ±‡ã€æƒ…ç»ªå¼ºåº¦ï¼‰
2. ç¤¾ç¾¤æ´»è·ƒåº¦æ˜¯å¦ä¸Šå‡ï¼ˆåŸºäºæ¶ˆæ¯é¢‘ç‡ã€è®¨è®ºçƒ­åº¦ã€äº’åŠ¨æ€§ï¼‰
3. å½“å‰çš„çƒ­ç‚¹è¯é¢˜

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼š
{
    "volatility_increased": true/false,
    "activity_increased": true/false,
    "summary": "ç®€çŸ­è¯´æ˜åŸå› å’Œå¸‚åœºçŠ¶å†µ",
    "hot_topics": ["è¯é¢˜1", "è¯é¢˜2", "è¯é¢˜3"],
    "confidence": 0.0-1.0
}"""

        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ {len(recent_messages)} æ¡åŠ å¯†è´§å¸ Telegram æ¶ˆæ¯ï¼Œåˆ¤æ–­å¸‚åœºæ³¢åŠ¨ç‡å’Œç¤¾ç¾¤æ´»è·ƒåº¦æ˜¯å¦ä¸Šå‡ï¼š

{combined_text}

è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¿”å›åˆ†æç»“æœã€‚"""

        response = self._call_qwen_api(user_prompt, system_prompt)

        if not response:
            return None

        try:
            # å°è¯•æå– JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown ä»£ç å—ï¼‰
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.startswith("```"):
                response = response[3:]
            if response.endswith("```"):
                response = response[:-3]

            result = json.loads(response.strip())
            return result

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {e}")
            logger.error(f"Response was: {response}")
            return None

    def analyze_messages(self) -> None:
        """
        æ‰§è¡Œå®šæœŸåˆ†æï¼šæ¯ N æ¡æ¶ˆæ¯è¿›è¡Œä¸€æ¬¡æ‘˜è¦å’Œæ³¢åŠ¨ç‡åˆ¤æ–­
        """
        logger.info(
            f"Starting analysis at message count: {self.message_count} "
            f"(buffer size: {len(self.message_buffer)})"
        )

        # 1. ç”Ÿæˆæ¶ˆæ¯æ‘˜è¦
        summary = self.summarize_recent_messages(num_messages=100)
        if summary:
            logger.success(f"Message Summary:\n{summary}")
        else:
            logger.warning("Failed to generate summary")

        # 2. åˆ†æå¸‚åœºæ³¢åŠ¨ç‡
        volatility_result = self.analyze_market_volatility(num_messages=500)

        if volatility_result:
            logger.info(f"Volatility Analysis Result: {json.dumps(volatility_result, ensure_ascii=False, indent=2)}")

            # 3. å¦‚æœæ³¢åŠ¨ç‡æˆ–æ´»è·ƒåº¦ä¸Šå‡ï¼Œå‘é€é‚®ä»¶
            if volatility_result.get("volatility_increased") or volatility_result.get(
                "activity_increased"
            ):
                self._send_alert_email(volatility_result, summary)
            else:
                logger.info("No significant market volatility or activity increase detected")
        else:
            logger.warning("Failed to analyze market volatility")

    def _send_alert_email(
        self, volatility_result: Dict, summary: Optional[str]
    ) -> None:
        """
        å‘é€å¸‚åœºæ³¢åŠ¨è­¦æŠ¥é‚®ä»¶

        Args:
            volatility_result: æ³¢åŠ¨ç‡åˆ†æç»“æœ
            summary: æ¶ˆæ¯æ‘˜è¦
        """
        # æ„å»ºé‚®ä»¶å†…å®¹
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        volatility_status = (
            "ğŸ“ˆ **ä¸Šå‡**" if volatility_result.get("volatility_increased") else "ğŸ“Š æ­£å¸¸"
        )
        activity_status = (
            "ğŸ”¥ **ä¸Šå‡**" if volatility_result.get("activity_increased") else "ğŸ’¤ æ­£å¸¸"
        )

        hot_topics = volatility_result.get("hot_topics", [])
        hot_topics_md = (
            "\n".join([f"- {topic}" for topic in hot_topics])
            if hot_topics
            else "æš‚æ— æ˜æ˜¾çƒ­ç‚¹"
        )

        confidence = volatility_result.get("confidence", 0.0)
        confidence_bar = "ğŸŸ¢" * int(confidence * 10) + "âšª" * (10 - int(confidence * 10))

        email_content = f"""# ğŸš¨ å¸‚åœºæ³¢åŠ¨ç‡è­¦æŠ¥

**åˆ†ææ—¶é—´**: {timestamp}
**åˆ†ææ¶ˆæ¯æ•°**: {len(self.message_buffer)} æ¡
**ç´¯è®¡æ¶ˆæ¯æ•°**: {self.message_count} æ¡

---

## ğŸ“Š åˆ†æç»“æœ

### å¸‚åœºæ³¢åŠ¨ç‡
{volatility_status}

### ç¤¾ç¾¤æ´»è·ƒåº¦
{activity_status}

### ç½®ä¿¡åº¦
{confidence_bar} {confidence:.1%}

---

## ğŸ”¥ å½“å‰çƒ­ç‚¹è¯é¢˜

{hot_topics_md}

---

## ğŸ“ å¸‚åœºçŠ¶å†µè¯´æ˜

{volatility_result.get('summary', 'æš‚æ— è¯¦ç»†è¯´æ˜')}

---

## ğŸ“° æœ€è¿‘æ¶ˆæ¯æ‘˜è¦

{summary or 'æš‚æ— æ‘˜è¦'}

---

*æœ¬é‚®ä»¶ç”± Market Insight Bot è‡ªåŠ¨ç”Ÿæˆ*
*AI æ¨¡å‹: {self.model}*
"""

        subject = f"[Market Alert] å¸‚åœºæ³¢åŠ¨ç‡ä¸Šå‡ - {timestamp}"

        try:
            success = send_markdown_email(subject, email_content)
            if success:
                logger.success(f"Alert email sent successfully: {subject}")
            else:
                logger.error("Failed to send alert email")
        except Exception as e:
            logger.error(f"Error sending alert email: {e}")

    def get_stats(self) -> Dict[str, int]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        return {
            "total_messages": self.message_count,
            "buffer_size": len(self.message_buffer),
            "last_analysis_count": self.last_analysis_count,
            "next_analysis_at": self.last_analysis_count + self.analysis_interval,
        }


# å…¨å±€åˆ†æå™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
_analyzer_instance = None


def get_analyzer(**kwargs) -> NewsAnalyzer:
    """
    è·å–å…¨å±€åˆ†æå™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Args:
        **kwargs: NewsAnalyzer åˆå§‹åŒ–å‚æ•°

    Returns:
        NewsAnalyzer å®ä¾‹
    """
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = NewsAnalyzer(**kwargs)
    return _analyzer_instance


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import time

    analyzer = NewsAnalyzer()

    # æ¨¡æ‹Ÿæ·»åŠ æ¶ˆæ¯
    test_messages = [
        {
            "channel": "CryptoNews",
            "text": "BTCçªç ´45000ç¾å…ƒï¼Œå¸‚åœºæƒ…ç»ªé«˜æ¶¨ï¼",
            "date": datetime.now().isoformat(),
            "message_id": 1,
        },
        {
            "channel": "TechFlow",
            "text": "ä»¥å¤ªåŠå³å°†å®Œæˆä¸Šæµ·å‡çº§ï¼Œè´¨æŠ¼ææ¬¾åŠŸèƒ½å¼€å¯",
            "date": datetime.now().isoformat(),
            "message_id": 2,
        },
        {
            "channel": "BlockBeats",
            "text": "Binanceå®£å¸ƒæ”¯æŒæ–°çš„è´¨æŠ¼äº§å“",
            "date": datetime.now().isoformat(),
            "message_id": 3,
        },
    ]

    for msg in test_messages:
        analyzer.add_message(msg)

    # æµ‹è¯•æ‘˜è¦åŠŸèƒ½
    print("\n=== æµ‹è¯•æ‘˜è¦åŠŸèƒ½ ===")
    summary = analyzer.summarize_recent_messages(num_messages=3)
    print(f"Summary: {summary}")

    # æµ‹è¯•æ³¢åŠ¨ç‡åˆ†æ
    print("\n=== æµ‹è¯•æ³¢åŠ¨ç‡åˆ†æ ===")
    volatility = analyzer.analyze_market_volatility(num_messages=3)
    print(f"Volatility: {json.dumps(volatility, ensure_ascii=False, indent=2)}")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n=== ç»Ÿè®¡ä¿¡æ¯ ===")
    stats = analyzer.get_stats()
    print(json.dumps(stats, indent=2))
